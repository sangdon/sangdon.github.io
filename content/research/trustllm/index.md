---
title: Trustworthy LLMs 
summary: Make LLMs trustful, fair, safe, and secue.
#date: 2025-02-18
reading_time: false
weight: 9

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'ChatGPT 4o'

authors:
  - Sangdon Park

#tags:
#  - Academic
#  - Markdown
  
share: false
toc: false

---


Large language models are amazingly performant and we use them our daily life. Simultaneously, they raises many practical issues, including halluciation and harmful responses. This raises the following question.

> **How to mitigate the <mark>hallucination</mark>, <mark>safety</mark>, <mark>security</mark>, and <mark>bias</mark> problems of large language models (LLMs) or large reasoning models (LRMs)?**


LLMs confidently generate wrong, biased, and harmful information, which undermines the trust of LLMs as a knowledge base.
How to mitigate this?
One way could be leveraging conformal prediction and selective prediction to measure uncertainty as a basis for trust (e.g., [NeurIPS'24](https://arxiv.org/abs/2307.09254)).
What other possibilities?


### On-going/Potential Projects

* Mitigate the {halluciation, safety, security} of LRMs.
* Quantify the correctness of the answers of LLMs or LRMs.    
* Leverage bandits and Reinforcment Learning (RL) for building trustworthy LLMs.
* Lerverage theoretical results of bandits or RL to guarantee the trustworthiness.
* Learn LLMs free from jailbreaking.

What's your own project idea?


### Keywords
* LLMs
* LRMs
* Selective Prediction
* Conformal Prediction
* Uncertainty Quantification 

### Related Work
* [ICLR'20](https://openreview.net/forum?id=BJxVI04YvB)
* [AISTATS'20](http://proceedings.mlr.press/v108/park20b/park20b.pdf)
* [ICLR'21](https://openreview.net/forum?id=Qk-Wq5AIjpq)
* [ICLR'22](https://openreview.net/pdf?id=DhP9L8vIyLc)
* [arXiv'22](https://arxiv.org/abs/2204.07482)
* [NeurIPS'22](https://openreview.net/forum?id=s6ygs1UCOw1)
* [Security'23](https://www.usenix.org/conference/usenixsecurity23/presentation/park)
* [NeurIPS'24](https://arxiv.org/abs/2307.09254)
* [arXiv'25](https://arxiv.org/abs/2506.14067)
* [arXiv'25](https://arxiv.org/abs/2505.13553)

