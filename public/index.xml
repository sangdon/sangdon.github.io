<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sangdon Park</title><link>http://localhost:1313/</link><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml"/><description>Sangdon Park</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 24 Oct 2023 00:00:00 +0000</lastBuildDate><image><url>http://localhost:1313/media/icon_hu_5e0546d98affa013.png</url><title>Sangdon Park</title><link>http://localhost:1313/</link></image><item><title>Red Teaming</title><link>http://localhost:1313/research/redteaming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/redteaming/</guid><description/></item><item><title>Trustworthy Code Generation</title><link>http://localhost:1313/research/coegen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/coegen/</guid><description/></item><item><title>Machine Unlearning</title><link>http://localhost:1313/research/unlearning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/unlearning/</guid><description/></item><item><title>Uncertainty Quantification</title><link>http://localhost:1313/research/uq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/uq/</guid><description>&lt;blockquote>
&lt;p>&lt;strong>Can we rigorously learn and quantify the uncertainty of AI models, e.g., Large Language Models (LLMs), price predictors, or drones, under distribution shift and adversarial manipulation?&lt;/strong>&lt;/p>&lt;/blockquote>
&lt;p>Quantified uncertainty of AI models&amp;rsquo; predictions provides a basis of the trust on predictions.
To rigorously quantify uncertainty,
we have mainly leveraged learning theory, calibration, and conformal prediction.&lt;/p>
&lt;p>&lt;strong>Keywords&lt;/strong>: &lt;em>uncertainty quantification&lt;/em>, &lt;em>calibration&lt;/em>, &lt;em>conformal prediction&lt;/em>, &lt;em>learning theory&lt;/em>, &lt;em>distribution shift&lt;/em>&lt;/p>
&lt;p>&lt;strong>Related Work&lt;/strong>:
&lt;a href="https://openreview.net/forum?id=BJxVI04YvB" target="_blank" rel="noopener">ICLR'20&lt;/a>,
&lt;a href="http://proceedings.mlr.press/v108/park20b/park20b.pdf" target="_blank" rel="noopener">AISTATS'20&lt;/a>,
&lt;a href="https://openreview.net/forum?id=Qk-Wq5AIjpq" target="_blank" rel="noopener">ICLR'21&lt;/a>,
&lt;a href="https://openreview.net/pdf?id=DhP9L8vIyLc" target="_blank" rel="noopener">ICLR'22&lt;/a>,
&lt;a href="https://arxiv.org/abs/2204.07482" target="_blank" rel="noopener">arXiv'22&lt;/a>,
&lt;a href="https://openreview.net/forum?id=s6ygs1UCOw1" target="_blank" rel="noopener">NeurIPS'22&lt;/a>,
&lt;a href="https://www.usenix.org/conference/usenixsecurity23/presentation/park" target="_blank" rel="noopener">Security'23&lt;/a>,
&lt;a href="https://arxiv.org/abs/2307.09254" target="_blank" rel="noopener">NeurIPS'24&lt;/a>&lt;/p></description></item><item><title>Trustworthy LLMs</title><link>http://localhost:1313/research/trustllm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/trustllm/</guid><description>&lt;blockquote>
&lt;p>&lt;strong>How to mitigate the &lt;mark>hallucination&lt;/mark>, &lt;mark>safety&lt;/mark>, &lt;mark>security&lt;/mark>, and &lt;mark>bias&lt;/mark> problems of LLMs?&lt;/strong>&lt;/p>&lt;/blockquote>
&lt;p>LMMs confidently generate wrong information, which undermines the trust of LLMs as a knowledge base.
How to mitigate this?
One way could be leveraging conformal prediction and selective prediction to measure uncertainty as a basis for trust (e.g., &lt;a href="https://arxiv.org/abs/2307.09254" target="_blank" rel="noopener">NeurIPS'24&lt;/a>).
What other possibilities?&lt;/p>
&lt;p>&lt;strong>Keywords&lt;/strong>: &lt;em>uncertainty quantification&lt;/em>, &lt;em>conformal prediction&lt;/em>, &lt;em>selective prediction&lt;/em>, &lt;em>LLMs&lt;/em>&lt;/p>
&lt;p>&lt;strong>Related Work&lt;/strong>:
&lt;a href="https://openreview.net/forum?id=BJxVI04YvB" target="_blank" rel="noopener">ICLR'20&lt;/a>,
&lt;a href="http://proceedings.mlr.press/v108/park20b/park20b.pdf" target="_blank" rel="noopener">AISTATS'20&lt;/a>,
&lt;a href="https://openreview.net/forum?id=Qk-Wq5AIjpq" target="_blank" rel="noopener">ICLR'21&lt;/a>,
&lt;a href="https://openreview.net/pdf?id=DhP9L8vIyLc" target="_blank" rel="noopener">ICLR'22&lt;/a>,
&lt;a href="https://arxiv.org/abs/2204.07482" target="_blank" rel="noopener">arXiv'22&lt;/a>,
&lt;a href="https://openreview.net/forum?id=s6ygs1UCOw1" target="_blank" rel="noopener">NeurIPS'22&lt;/a>,
&lt;a href="https://www.usenix.org/conference/usenixsecurity23/presentation/park" target="_blank" rel="noopener">Security'23&lt;/a>,
&lt;a href="https://arxiv.org/abs/2307.09254" target="_blank" rel="noopener">NeurIPS'24&lt;/a>&lt;/p></description></item><item><title>AI Alignment</title><link>http://localhost:1313/research/ai-alignment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/research/ai-alignment/</guid><description/></item><item><title>ChronoBias: A Benchmark for Evaluating Temporal Group Bias in Retrieval-augmented Language Models</title><link>http://localhost:1313/publication/kim-2025-chronobias/</link><pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/kim-2025-chronobias/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Retrieval-Augmented Generation with Estimation of Source Reliability</title><link>http://localhost:1313/publication/hwang-2025-retrievalaugmented/</link><pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/hwang-2025-retrievalaugmented/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Holistic Unlearning Benchmark: A Multi-Faceted Evaluation for Text-to-Image Diffusion Model Unlearning</title><link>http://localhost:1313/publication/moon-2025-holisticunlearningbenchmarkmultifaceted/</link><pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/moon-2025-holisticunlearningbenchmarkmultifaceted/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>üßë‚Äç‚öñÔ∏è Area Chair</title><link>http://localhost:1313/news/20250905-iclr-ac/</link><pubDate>Fri, 05 Sep 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250905-iclr-ac/</guid><description/></item><item><title>üéâ Two EMNLP Papers</title><link>http://localhost:1313/news/20250821-emnlp/</link><pubDate>Thu, 21 Aug 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250821-emnlp/</guid><description>&lt;p>Congrat to Kyungmin and Jeongyeon!&lt;/p></description></item><item><title>üèÜ DARPA AIxCC Winner!</title><link>http://localhost:1313/news/20250808-2-aixcc-final/</link><pubDate>Fri, 08 Aug 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250808-2-aixcc-final/</guid><description>&lt;p>Our &lt;a href="https://team-atlanta.github.io/" target="_blank" rel="noopener">Team Atlanta&lt;/a> won &lt;a href="https://aicyberchallenge.com/" target="_blank" rel="noopener">DARPA AIxCC&lt;/a> with a $4M award &amp;ndash; &lt;a href="https://www.darpa.mil/news/2025/aixcc-results" target="_blank" rel="noopener">official announcement&lt;/a>. This team consists of Samsung, GaTech, KAIST, and POSTECH (us!), led by Taesoo Kim (Samsung and GaTech). I led the POSTECH team, which includes my students, Minjae Gwon (POSTECH CSE) and Minjae Lee (POSTECH AI). My team focuses on patch generation mainly leveraging custom models. We will continue our journey to build &lt;strong>trustworthy&lt;/strong> patch/code generation toward practical applications.&lt;/p>
&lt;p>I&amp;rsquo;m fortunate to be in this amazing team and grateful to Prof. Taesoo Kim who built and led this amazing team!&lt;/p>
&lt;p>POSTECH GSAI supports GPUs for our team.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="POSTECH" srcset="
/news/20250808-2-aixcc-final/AIxCC-POSTECH_hu_6d1233b4ff884e57.webp 400w,
/news/20250808-2-aixcc-final/AIxCC-POSTECH_hu_c43db5e52334886f.webp 760w,
/news/20250808-2-aixcc-final/AIxCC-POSTECH_hu_70fc609b076fa86c.webp 1200w"
src="http://localhost:1313/news/20250808-2-aixcc-final/AIxCC-POSTECH_hu_6d1233b4ff884e57.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="https://img.global.news.samsung.com/global/wp-content/uploads/2025/08/Samsung-Corporate-Technology-AIxCC-First-Place-in-AI-Cyber-Challenge_main1.jpg" alt="Samsung" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>üèÜ Best Paper Finalist</title><link>http://localhost:1313/news/20250807-1-ckaia-award/</link><pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250807-1-ckaia-award/</guid><description>&lt;p>Congrat to Minjae and Yoonjae!
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="awardfig1" srcset="
/news/20250807-1-ckaia-award/fig1_hu_a5cd4b48f44c9eac.webp 400w,
/news/20250807-1-ckaia-award/fig1_hu_e4c51860f3d11472.webp 760w,
/news/20250807-1-ckaia-award/fig1_hu_8f93eb3df1b80220.webp 1200w"
src="http://localhost:1313/news/20250807-1-ckaia-award/fig1_hu_a5cd4b48f44c9eac.webp"
width="760"
height="570"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img alt="awardfig2" srcset="
/news/20250807-1-ckaia-award/fig2_hu_8f14930ff0982b60.webp 400w,
/news/20250807-1-ckaia-award/fig2_hu_2f6ecf7d5ee6034.webp 760w,
/news/20250807-1-ckaia-award/fig2_hu_b9f3bd83486ec5b1.webp 1200w"
src="http://localhost:1313/news/20250807-1-ckaia-award/fig2_hu_8f14930ff0982b60.webp"
width="570"
height="760"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>A Regret Perspective on Online Selective Generation</title><link>http://localhost:1313/publication/lee-2025-regretperspectiveonlineselective/</link><pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/lee-2025-regretperspectiveonlineselective/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Selective Code Generation for Functional Guarantees</title><link>http://localhost:1313/publication/jeong-2025-selectivecodegenerationfunctional/</link><pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/jeong-2025-selectivecodegenerationfunctional/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>üéâ One ICCV'25 Paper</title><link>http://localhost:1313/news/20250626-iccv/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250626-iccv/</guid><description>&lt;p>Congrat to Saemi and Minjong!&lt;/p></description></item><item><title>SOUNDBOOST: Effective RCA and Attack Detection for UAV via Acoustic Side-Channel</title><link>http://localhost:1313/publication/wang-2025-soundboost/</link><pubDate>Sun, 01 Jun 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/wang-2025-soundboost/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>üéâ One DSN'25 Paper</title><link>http://localhost:1313/news/20250520-dsn/</link><pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250520-dsn/</guid><description/></item><item><title>üèÜ Graduate Fellowship</title><link>http://localhost:1313/news/20250416-fellowship/</link><pubDate>Wed, 16 Apr 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250416-fellowship/</guid><description>&lt;p>Congrat to Jaewoo!&lt;/p>
&lt;p>&lt;a href="">award&lt;/a>&lt;/p></description></item><item><title>üìö Trustworthy ML (2025 Spring)</title><link>http://localhost:1313/teaching/2025-tml-spring/</link><pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/teaching/2025-tml-spring/</guid><description>&lt;h1 id="trustworthy-ml-aigs703l--csed703l">Trustworthy ML (AIGS703L / CSED703L)&lt;/h1>
&lt;p>As machine learning and deep learning models are impacting on real world environments (e.g., ChatGPT), concerns on the trustworthiness of machine-learned models are rising. In this course, we explore whether popular machine-learned models are trustworthy and then study various learning methods to enchant the models to be trustworthy. To this end, we will learn basic knowledge on machine learning theory, uncertainty learning via conformal prediction, adversarial examples/learning, machine unlearning, differentially private learning, fairness in learning, and miscellaneous topics on trustworthy generative AI.&lt;/p>
&lt;h3 id="location">Location&lt;/h3>
&lt;p>B2 Room 107&lt;/p>
&lt;h3 id="instructor">Instructor&lt;/h3>
&lt;p>Sangdon Park&lt;/p>
&lt;h3 id="teaching-assistant">Teaching Assistant&lt;/h3>
&lt;p>Byeonggyu Kim (&lt;a href="mailto:qudrb6989@postech.ac.kr">qudrb6989@postech.ac.kr&lt;/a>)&lt;/p>
&lt;h3 id="schedule">Schedule&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;div style="width:100px">Date&lt;/div>&lt;/th>
&lt;th>Topic&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>[W1] 2/18&lt;/td>
&lt;td>&lt;a href="./notes/0-intro.pdf">Trustworthy ML Introduction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W1] 2/20&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-measure.pdf">Measure Theory: Introduction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W2] 2/25&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-pac.pdf">Learning Theory: PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W2] 2/27&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-pac.pdf">Learning Theory: PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W3] 3/4&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W3] 3/6&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W4] 3/11&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W4] 3/13&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W5] 3/18&lt;/td>
&lt;td>&lt;a href="./notes/2-cp.pdf">Controllable Uncertainty Learning: Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W5] 3/20&lt;/td>
&lt;td>&lt;a href="./notes/2-cp.pdf">Controllable Uncertainty Learning: Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W6] 3/25&lt;/td>
&lt;td>&lt;a href="./notes/2-paccp.pdf">Controllable Uncertainty Learning: PAC Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W6] 3/27&lt;/td>
&lt;td>&lt;a href="./notes/2-acp.pdf">Controllable Uncertainty Learning: Adaptive Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W7] 4/1&lt;/td>
&lt;td>&lt;a href="./notes/2-sp.pdf">Controllable Uncertainty Learning: Selective Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W7] 4/3&lt;/td>
&lt;td>&lt;a href="./notes/3-ae.pdf">Adversarial Learning: Adversarial Examples and Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W8] 4/8&lt;/td>
&lt;td>&lt;a href="./notes/3-cert.pdf">Adversarial Learning: Certified Adversarial Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W8] 4/10&lt;/td>
&lt;td>&lt;a href="./notes/3-cert.pdf">Adversarial Learning: Certified Adversarial Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W9] 4/15&lt;/td>
&lt;td>&lt;a href="./notes/5-dp1.pdf">Differential Privacy: Basics&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W9] 4/17&lt;/td>
&lt;td>&lt;a href="./notes/5-dp1.pdf">Differential Privacy: Basics&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W10] 4/22&lt;/td>
&lt;td>&lt;a href="./notes/5-dp2.pdf">Differential Privacy: Practice&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W10] 4/24&lt;/td>
&lt;td>&lt;a href="./notes/4-cul.pdf">Machine Unlearning: Linear Models&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W11] 4/29&lt;/td>
&lt;td>&lt;a href="./notes/4-cul.pdf">Machine Unlearning: Linear Models&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W11] 5/1&lt;/td>
&lt;td>&lt;a href="./notes/4-cul2.pdf">Machine Unlearning: Deep Models&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W12] 5/6&lt;/td>
&lt;td>Children&amp;rsquo;s Day (Extended)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W12] 5/8&lt;/td>
&lt;td>&lt;a href="./notes/6-fair1.pdf">Fairness in Learning: Foundation&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W13] 5/13&lt;/td>
&lt;td>&lt;a href="">Miscellaneous Topics in TML&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W13] 5/15&lt;/td>
&lt;td>Student Presentation 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W14] 5/20&lt;/td>
&lt;td>Student Presentation 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W14] 5/22&lt;/td>
&lt;td>Student Presentation 3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W15] 5/27&lt;/td>
&lt;td>Student Presentation 4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W15] 5/29&lt;/td>
&lt;td>Student Presentation 5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W16] 6/3&lt;/td>
&lt;td>Student Presentation 6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[W16] 6/5&lt;/td>
&lt;td>Final Exam&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>üßë‚Äç‚öñÔ∏è Area Chair</title><link>http://localhost:1313/news/20240327-neurips-ac/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240327-neurips-ac/</guid><description/></item><item><title>üèÜ Best Paper Award</title><link>http://localhost:1313/news/20250106-award/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250106-award/</guid><description>&lt;p>Congrat to Kyungmin and Minjae!&lt;/p></description></item><item><title>üéâ 2024 Summary</title><link>http://localhost:1313/news/20241231-summary/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20241231-summary/</guid><description>&lt;p>I appreciate all of my collaborators!&lt;/p></description></item><item><title>Selective Generation for Controllable Language Models</title><link>http://localhost:1313/publication/lee-2024-selective/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/lee-2024-selective/</guid><description/></item><item><title>üßë‚Äç‚öñÔ∏è Area Chair</title><link>http://localhost:1313/news/20241122-icml-ac/</link><pubDate>Fri, 22 Nov 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20241122-icml-ac/</guid><description/></item><item><title>üéâ One NeurIPS'24 Paper (Spotlight)</title><link>http://localhost:1313/news/20240926-neurips-paper/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240926-neurips-paper/</guid><description>&lt;p>Congrat to Minjae and Kyungmin!&lt;/p></description></item><item><title>üé§ Invite Talk</title><link>http://localhost:1313/news/20240910-invited-talk/</link><pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240910-invited-talk/</guid><description/></item><item><title>üé§ Breakout Session</title><link>http://localhost:1313/news/20240909-reaim/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240909-reaim/</guid><description>&lt;p>Check out &lt;a href="https://reaim2024.kr/" target="_blank" rel="noopener">Responsible AI in the Military Domain (REAIM)&lt;/a> Summit.&lt;/p></description></item><item><title>üìö Trustworthy ML (2024 Fall)</title><link>http://localhost:1313/teaching/2024-tml-fall/</link><pubDate>Tue, 03 Sep 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/teaching/2024-tml-fall/</guid><description>&lt;h1 id="trustworthy-ml-aigs703l--csed703l">Trustworthy ML (AIGS703L / CSED703L)&lt;/h1>
&lt;p>As machine learning and deep learning models are impacting on real world environments (e.g., ChatGPT), concerns on the trustworthiness of machine-learned models are rising. In this course, we explore whether popular machine-learned models are trustworthy and then study various learning methods to enchant the models to be trustworthy. To this end, we will learn basic knowledge on machine learning theory, uncertainty learning via conformal prediction, adversarial examples/learning, machine unlearning, differentially private learning, fairness in learning, and miscellaneous topics on trustworthy generative AI.&lt;/p>
&lt;h3 id="location">Location&lt;/h3>
&lt;p>TJ Park Lib. Room 501&lt;/p>
&lt;h3 id="instructor">Instructor&lt;/h3>
&lt;p>Sangdon Park&lt;/p>
&lt;h3 id="teaching-assistant">Teaching Assistant&lt;/h3>
&lt;p>Kyungmin Kim (&lt;a href="mailto:kkm959595@postech.ac.kr">kkm959595@postech.ac.kr&lt;/a>)&lt;/p>
&lt;h3 id="schedule">Schedule&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;div style="width:150px">Date&lt;/div>&lt;/th>
&lt;th>Topic&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>[Week 1] 9/3&lt;/td>
&lt;td>&lt;a href="./notes/0-intro.pdf">Trustworthy ML Introduction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 1] 9/5&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-measure.pdf">Measure Theory: Introduction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 2] 9/10&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-pac.pdf">Learning Theory: PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 2] 9/12&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 3] 9/17&lt;/td>
&lt;td>Korean Thanksgiving holiday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 3] 9/19&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 4] 9/24&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 4] 9/26&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 5] 10/1&lt;/td>
&lt;td>Armed Forces Day&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 5] 10/3&lt;/td>
&lt;td>National Foundation Day&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 6] 10/8&lt;/td>
&lt;td>&lt;a href="./notes/2-cp.pdf">Controllable Uncertainty Learning: Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 6] 10/10&lt;/td>
&lt;td>&lt;a href="./notes/2-paccp.pdf">Controllable Uncertainty Learning: PAC Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 7] 10/15&lt;/td>
&lt;td>&lt;a href="./notes/2-acp.pdf">Controllable Uncertainty Learning: Adaptive Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 7] 10/17&lt;/td>
&lt;td>&lt;a href="./notes/2-sp.pdf">Controllable Uncertainty Learning: Selective Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 8] 10/22&lt;/td>
&lt;td>&lt;a href="./notes/3-ae.pdf">Adversarial Learning: Adversarial Examples and Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 8] 10/24&lt;/td>
&lt;td>&lt;a href="./notes/3-cert.pdf">Adversarial Learning: Certified Adversarial Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 9] 10/29&lt;/td>
&lt;td>&lt;a href="./notes/5-dp1.pdf">Differential Privacy: Basics&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 9] 10/31&lt;/td>
&lt;td>&lt;a href="./notes/5-dp2.pdf">Differential Privacy: Practice&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 10] 11/5&lt;/td>
&lt;td>&lt;a href="./notes/4-cul.pdf">Machine Unlearning: Linear Models&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 10] 11/7&lt;/td>
&lt;td>&lt;a href="./notes/4-cul2.pdf">Machine Unlearning: Deep Models&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 11] 11/12&lt;/td>
&lt;td>&lt;a href="./notes/6-fair1.pdf">Fairness in Learning: Foundation&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 11] 11/14&lt;/td>
&lt;td>[Fairness in Learning: NLP Application]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 12] 11/19&lt;/td>
&lt;td>Miscellaneous Topics in TML&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 12] 11/21&lt;/td>
&lt;td>Final Exam&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 13] 11/26&lt;/td>
&lt;td>Student Discussion 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 13] 11/28&lt;/td>
&lt;td>Student Discussion 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 14] 12/3&lt;/td>
&lt;td>Student Discussion 3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 14] 12/5&lt;/td>
&lt;td>Student Discussion 4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 15] 12/10&lt;/td>
&lt;td>Student Discussion 5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 15] 12/12&lt;/td>
&lt;td>Student Discussion 6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 16] 12/17&lt;/td>
&lt;td>Student Discussion 7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 16] 12/19&lt;/td>
&lt;td>Student Discussion 8&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>üèÜ DARPA AIxCC Semifinals</title><link>http://localhost:1313/news/20240812-aixcc-semifinals/</link><pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240812-aixcc-semifinals/</guid><description>&lt;p>&lt;a href="https://team-atlanta.github.io/" target="_blank" rel="noopener">Team Atlanta&lt;/a> advances to the &lt;a href="https://aicyberchallenge.com/" target="_blank" rel="noopener">DARPA AIxCC&lt;/a> finals with a $2M team award.&lt;/p></description></item><item><title>MedBN: Robust Test Time Adaptation against Malicious Test Samples</title><link>http://localhost:1313/publication/park-2024-medbn/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2024-medbn/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction</title><link>http://localhost:1313/publication/li-2024-shuo/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/li-2024-shuo/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>PAC Prediction Sets Under Label Shift</title><link>http://localhost:1313/publication/si-2024-pac/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/si-2024-pac/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>üßë‚Äç‚öñÔ∏è Area Chair</title><link>http://localhost:1313/news/20250217-neurips-ac/</link><pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20250217-neurips-ac/</guid><description/></item><item><title>üéâ One NAACL'24 Paper</title><link>http://localhost:1313/news/20240313-naacl-paper/</link><pubDate>Wed, 13 Mar 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240313-naacl-paper/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2307.04642" target="_blank" rel="noopener">TRAQ&lt;/a> is accepted to NAACL‚Äô24.&lt;/p></description></item><item><title>üéâ One CVPR'24 Paper</title><link>http://localhost:1313/news/20240227-cvpr-paper/</link><pubDate>Tue, 27 Feb 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240227-cvpr-paper/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2403.19326" target="_blank" rel="noopener">MedBN&lt;/a> is accepted to CVPR'24.&lt;/p></description></item><item><title>üìö Discrete Mathematics (2024 Sring)</title><link>http://localhost:1313/teaching/2024-discrete-math-spring/</link><pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/teaching/2024-discrete-math-spring/</guid><description>&lt;h1 id="discrete-mathematics-csed261">Discrete Mathematics (CSED261)&lt;/h1>
&lt;p>&lt;a href="https://plms.postech.ac.kr/course/view.php?id=9586" target="_blank" rel="noopener">Class Page&lt;/a>&lt;/p></description></item><item><title>üéâ One ICLR'24 Paper</title><link>http://localhost:1313/news/20240116-iclr-paper/</link><pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20240116-iclr-paper/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2310.12964" target="_blank" rel="noopener">Label Shift&lt;/a> is accepted to ICLR'24.&lt;/p></description></item><item><title>Angelic Patches for Improving Third-Party Object Detector Performance</title><link>http://localhost:1313/publication/wenwen-2023-angelic/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/wenwen-2023-angelic/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>üìö Trustworthy ML (2023 Fall)</title><link>http://localhost:1313/teaching/2023-tml-fall/</link><pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/teaching/2023-tml-fall/</guid><description>&lt;h1 id="trustworthy-ml-aigs703l--csed703l">Trustworthy ML (AIGS703L / CSED703L)&lt;/h1>
&lt;p>As machine learning and deep learning models are impacting on real world environments (e.g., ChatGPT), concerns on the trustworthiness of machine-learned models are rising. In this course, we explore whether popular machine-learned models are trustworthy and then study various learning methods to enchant the models to be trustworthy. To this end, we will learn basic knowledge on machine learning theory, uncertainty learning via conformal prediction, adversarial examples/learning, machine unlearning, differentially private learning, fairness in learning, and miscellaneous topics on trustworthy generative AI.&lt;/p>
&lt;h3 id="location">Location&lt;/h3>
&lt;p>B2 Room 107&lt;/p>
&lt;h3 id="instructor">Instructor&lt;/h3>
&lt;p>Sangdon Park&lt;/p>
&lt;h3 id="schedule-tentative">Schedule (tentative)&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;div style="width:150px">Date&lt;/div>&lt;/th>
&lt;th>Topic&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>[Week 1] 9/5&lt;/td>
&lt;td>&lt;a href="./notes/0-intro.pdf">Trustworthy ML Introduction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 1] 9/7&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-pac.pdf">Learning Theory: PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 2] 9/12&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 2] 9/14&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-uc.pdf">Learning Theory: Beyond PAC learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 3] 9/19&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 3] 9/21&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-online.pdf">Learning Theory: Online learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 4] 9/26&lt;/td>
&lt;td>&lt;a href="./notes/1-theory-sq.pdf">Learning Theory: Statistical Query&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 4] 9/28&lt;/td>
&lt;td>Korean Thanksgiving holiday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 5] 10/3&lt;/td>
&lt;td>National Foundation Day&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 5] 10/5&lt;/td>
&lt;td>&lt;a href="./notes/2-cp.pdf">Uncertainty Learning: Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 6] 10/10&lt;/td>
&lt;td>&lt;a href="./notes/2-paccp.pdf">Uncertainty Learning: PAC Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 6] 10/12&lt;/td>
&lt;td>&lt;a href="./notes/2-acp.pdf">Uncertainty Learning: Adaptive Conformal Prediction&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 7] 10/17&lt;/td>
&lt;td>Student Presentation 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 7] 10/19&lt;/td>
&lt;td>&lt;a href="./notes/3-ae.pdf">Adversarial Learning: Adversarial Example / Heuristic Adversarial Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 8] 10/24&lt;/td>
&lt;td>&lt;a href="./notes/3-cert.pdf">Adversarial Learning: Certified Adversarial Learning&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 8] 10/26&lt;/td>
&lt;td>&lt;a href="./notes/4-cul.pdf">Machine Unlearning 1&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 9] 10/31&lt;/td>
&lt;td>Student Presentation 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 9] 11/2&lt;/td>
&lt;td>&lt;a href="./notes/4-cul2.pdf">Machine Unlearning 2&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 10] 11/7&lt;/td>
&lt;td>&lt;a href="./notes/5-dp1.pdf">Differential Privacy 1&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 10] 11/9&lt;/td>
&lt;td>Student Presentation 3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 11] 11/14&lt;/td>
&lt;td>Student Presentation 3.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 11] 11/16&lt;/td>
&lt;td>&lt;a href="./notes/5-dp2.pdf">Differential Privacy 2&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 12] 11/21&lt;/td>
&lt;td>&lt;a href="./notes/6-fair1.pdf">Fairness in Learning 1&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 12] 11/23&lt;/td>
&lt;td>&lt;a href="./notes/6-fair2.pdf">Fairness in Learning 2&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 13] 11/28&lt;/td>
&lt;td>Student Presentation 4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 13] 11/30&lt;/td>
&lt;td>Student Presentation 5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 14] 12/5&lt;/td>
&lt;td>&lt;a href="./notes/7-codegen.pdf">Code Generation&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 14] 12/7&lt;/td>
&lt;td>&lt;a href="./notes/7-copyright.pdf">Copyright&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 15] 12/12&lt;/td>
&lt;td>Student Presentation 6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 15] 12/14&lt;/td>
&lt;td>Student Presentation 7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 16] 12/19&lt;/td>
&lt;td>Student Presentation 8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>[Week 16] 12/21&lt;/td>
&lt;td>Student Presentation 9&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>üéâ Assistant Professor</title><link>http://localhost:1313/news/20230801-start/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20230801-start/</guid><description/></item><item><title>üèÜ Best Paper Award</title><link>http://localhost:1313/news/20230801-award/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/news/20230801-award/</guid><description>&lt;p>&lt;a href="https://arxiv.org/abs/2307.04642" target="_blank" rel="noopener">TRAC&lt;/a> got a Best Paper award at ICML23 TEACH Workshop.&lt;/p></description></item><item><title>ACon$^2$: Adaptive Conformal Consensus for Provable Blockchain Oracles</title><link>http://localhost:1313/publication/park-2023-conformal/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2023-conformal/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>CODiT: Conformal Out-of-Distribution Detection in Time-Series Data for Cyber-Physical Systems</title><link>http://localhost:1313/publication/kaur-2023-codit/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/kaur-2023-codit/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>PAC Prediction Sets for Meta-Learning</title><link>http://localhost:1313/publication/park-2022-pac-b/</link><pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2022-pac-b/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Sequential Covariate Shift Detection Using Classifier Two-Sample Tests</title><link>http://localhost:1313/publication/jang-2021-covshift/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/jang-2021-covshift/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>PAC Prediction Sets Under Covariate Shift</title><link>http://localhost:1313/publication/park-2022-pac/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2022-pac/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Towards PAC Multi-Object Detection and Tracking</title><link>http://localhost:1313/publication/li-2022-pacmultiobjectdetectiontracking/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/li-2022-pacmultiobjectdetectiontracking/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering via Machine Learning</title><link>http://localhost:1313/publication/park-2022-unsafesbetrayalabusingunsafe/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2022-unsafesbetrayalabusingunsafe/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>PAC Confidence Predictions for Deep Neural Network Classifiers</title><link>http://localhost:1313/publication/park-2021-pac/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2021-pac/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>iDECODe: In-distribution Equivariance for Conformal Out-of-distribution Detection</title><link>http://localhost:1313/publication/kaur-2021-idecode/</link><pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/kaur-2021-idecode/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Calibrated prediction with covariate shift via unsupervised domain adaptation</title><link>http://localhost:1313/publication/park-2020-calibrated/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2020-calibrated/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction</title><link>http://localhost:1313/publication/park-2020-pac/</link><pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2020-pac/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Resilient linear classification: an approach to deal with attacks on training data</title><link>http://localhost:1313/publication/park-2017-resilient/</link><pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2017-resilient/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Integrated intelligence for human-robot teams</title><link>http://localhost:1313/publication/oh-2016-integrated/</link><pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/oh-2016-integrated/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Abnormal object detection by canonical scene-based contextual model</title><link>http://localhost:1313/publication/park-2012-abnormal/</link><pubDate>Mon, 01 Oct 2012 00:00:00 +0000</pubDate><guid>http://localhost:1313/publication/park-2012-abnormal/</guid><description>&lt;p>Add the &lt;strong>full text&lt;/strong> or &lt;strong>supplementary notes&lt;/strong> for the publication here using Markdown formatting.&lt;/p></description></item><item><title>Admin</title><link/><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid/><description/></item><item><title>Intern</title><link/><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid/><description/></item><item><title>Team</title><link>http://localhost:1313/team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/team/</guid><description/></item></channel></rss>